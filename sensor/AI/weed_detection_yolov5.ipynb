{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yolo_Directory = 'weedai_yolo'\n",
    "\n",
    "!mkdir /content/drive/MyDrive/{Yolo_Directory}\n",
    "%ls '/content/drive/MyDrive/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/drive/MyDrive/{Yolo_Directory}\n",
    "!git clone https://github.com/ultralytics/yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yolo_Dataset = 'weeddata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir /content/drive/MyDrive/{Yolo_Directory}/yolov5/datasets\n",
    "%cd '/content/drive/MyDrive/{Yolo_Directory}/yolov5/datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -q /content/drive/MyDrive/weeddata.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def coco_to_yolo(file, image_dir, output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    elif os.listdir(output_dir):\n",
    "        print(\"output_dir에 파일이 이미 존재합니다. 실행을 중단합니다.\")\n",
    "        return\n",
    "\n",
    "    with open(file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    images = {img['id']: img['file_name'] for img in data['images']}\n",
    "    categories = {cat['id']: cat['name'] for cat in data['categories']}\n",
    "\n",
    "    annotations = {}\n",
    "    for ann in data['annotations']:\n",
    "        image_id = ann['image_id']\n",
    "        cat_id = ann['category_id']\n",
    "        bbox = ann['bbox']\n",
    "\n",
    "        img_file = images[image_id]\n",
    "        img = Image.open(os.path.join(image_dir, img_file))\n",
    "        width, height = img.size\n",
    "        x_center = (bbox[0] + bbox[2] / 2) / width\n",
    "        y_center = (bbox[1] + bbox[3] / 2) / height\n",
    "        w = bbox[2] / width\n",
    "        h = bbox[3] / height\n",
    "\n",
    "        if image_id not in annotations:\n",
    "            annotations[image_id] = []\n",
    "        annotations[image_id].append((cat_id, x_center, y_center, w, h))\n",
    "\n",
    "    for image_id, objects in annotations.items():\n",
    "        file_name = images[image_id].replace('.jpg', '.txt').replace('.png', '.txt')\n",
    "        with open(os.path.join(output_dir, file_name), 'w') as f:\n",
    "            for obj in objects:\n",
    "                f.write(f\"{obj[0]} {obj[1]} {obj[2]} {obj[3]} {obj[4]}\\n\")\n",
    "\n",
    "coco_file = '/content/drive/MyDrive/weedai_yolo/yolov5/datasets/weedcoco.json'\n",
    "image_dir = '/content/drive/MyDrive/weedai_yolo/yolov5/datasets/images'\n",
    "output_dir = '/content/drive/MyDrive/weedai_yolo/yolov5/datasets/labels'\n",
    "\n",
    "coco_to_yolo(coco_file, image_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEED_COCO_LOCATION = f\"/content/drive/MyDrive/{Yolo_Directory}/yolov5/datasets\"\n",
    "# #convert the weedcoco file\n",
    "# convert_weedcoco_json(json_dir=WEED_COCO_LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read images and annotations\n",
    "images = [os.path.join(f'{WEED_COCO_LOCATION}/images', x) for x in os.listdir(f'{WEED_COCO_LOCATION}/images')]\n",
    "annotations = [os.path.join(f'{WEED_COCO_LOCATION}/labels', x) for x in os.listdir(f'{WEED_COCO_LOCATION}/labels') if x[-3:] == \"txt\"]\n",
    "\n",
    "images.sort()\n",
    "annotations.sort()\n",
    "\n",
    "# Split the dataset into train-val-test splits 80-10-10%\n",
    "train_images, val_images, train_annotations, val_annotations = train_test_split(images, annotations, test_size = 0.2, random_state = 1)\n",
    "val_images, test_images, val_annotations, test_annotations = train_test_split(val_images, val_annotations, test_size = 0.5, random_state = 1)\n",
    "\n",
    "%cd {WEED_COCO_LOCATION}\n",
    "!mkdir images/train images/val images/test labels/train labels/val labels/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility function to move images\n",
    "def move_files_to_folder(list_of_files, destination_folder):\n",
    "    for f in list_of_files:\n",
    "        try:\n",
    "            shutil.move(f, destination_folder)\n",
    "        except:\n",
    "            print(f)\n",
    "            assert False\n",
    "\n",
    "# Move the splits into their folders\n",
    "move_files_to_folder(train_images, 'images/train')\n",
    "move_files_to_folder(val_images, 'images/val/')\n",
    "move_files_to_folder(test_images, 'images/test/')\n",
    "move_files_to_folder(train_annotations, 'labels/train/')\n",
    "move_files_to_folder(val_annotations, 'labels/val/')\n",
    "move_files_to_folder(test_annotations, 'labels/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the images have been moved\n",
    "print(len(os.listdir('images/train')), len(os.listdir('labels/train')))\n",
    "print(len(os.listdir('images/val')), len(os.listdir('labels/val')))\n",
    "print(len(os.listdir('images/test')), len(os.listdir('labels/test')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import torch\n",
    "from IPython.display import Image  # for displaying images\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom import minidom\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "# print('torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train YOLOv5m\n",
    "BATCH = 8\n",
    "EPOCHS = 30\n",
    "IMAGE_SIZE = 640 # (should be one of 320, 640, 1280, 1920)\n",
    "MODEL = 'm' # (should be one of 'n', 's', 'm', 'l', 'x' and must be in lower case)\n",
    "\n",
    "# this is the name of your run, and how it will be saved\n",
    "RUN_NAME = f'datasets_TRAIN_B{str(BATCH)}_E{str(EPOCHS)}_SZ{str(IMAGE_SIZE)}_M{MODEL}'\n",
    "\n",
    "# avoid making any changes to the below, or check the Ultralytics docs for other commands\n",
    "!python train.py --img 640 --cfg yolov5{MODEL}.yaml --batch 8 --epochs 30 --data datasets/data.yaml --weights yolov5{MODEL}.pt --name {RUN_NAME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google-cloud-storage\n",
    "from google.cloud import storage\n",
    "from google.oauth2 import service_account\n",
    "from google.colab import drive\n",
    "from PIL import Image\n",
    "import os \n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "KEY_PATH = '/content/drive/MyDrive/keypath/omega-branch-396406-7356fbd5a834.json'\n",
    "credentials = service_account.Credentials.from_service_account_file(KEY_PATH)\n",
    "\n",
    "bucket_name = 'smartfarm-image'   \n",
    "source_blob_name = 'd8:3a:dd:27:ec:e0-20230821-111412.jpg'  \n",
    "destination_file_name = '/content/drive/MyDrive/images/file'    \n",
    "\n",
    "storage_client = storage.Client(credentials = credentials, project = credentials.project_id)\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "blob = bucket.blob(source_blob_name)\n",
    "blob.download_to_filename(destination_file_name)\n",
    "\n",
    "image_path = os.path.join(destination_file_name)\n",
    "\n",
    "\n",
    "#for detect\n",
    "DETECTION_FILES = image_path # e.g. 'test_video.mp4' OR test_image_directory OR test_image.jpg\n",
    "CONFIDENCE_THRESHOLD = 0.50 # this should be between 0 and 1. It changes the cutoff value for a detection. Lower = more sensitive, higher = less sensitive\n",
    "\n",
    "!python detect.py --source datasets/{DETECTION_FILES} --weights runs/train/{RUN_NAME}/weights/best.pt --name {RUN_NAME} --img {IMAGE_SIZE} --conf-thres 0.50"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
